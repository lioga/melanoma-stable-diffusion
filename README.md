# melanoma-stable-diffusion
This GitHub repository contains code and resources for creating a synthetic melanoma dataset using the power of stable diffusion and LoRa. More detailed explanation can be found in my [blog post](https://behlulakbudak.com/MedSynthX/).


# Introduction
Melanoma is a serious form of skin cancer that can affect anyone, regardless of age, gender, or ethnicity. It typically starts in the cells that produce skin pigment, called melanocytes. Melanoma is known for its ability to spread to other parts of the body, which makes early detection and prevention critical. 

# Data
The dataset was generated by the International Skin Imaging Collaboration ISIC[^1] , in the malignant_images folder some samples can be seen with its corresponding captions. In this competition there are so few melanoma images that the class imbalance was huge. Therefore, I wanted to see how I can utilize stable diffusion to generate synthetic images to reduce the impact of class imbalance.

# Preparing Dataset for Fine-tuning
I wanted to train a LoRa model with only melanoma images. So, I extract the melanoma images from the dataset and put them in a separate folder. The code for this can be found in the `separate_melanoma_images.py` file. After that I created captions by parsing information from the CSV file that was provided by the ISIC. The code for this can be found in the `create_captions.py` file. Lastly, I wanted to add hairy caption to the images that had hair. This is a very basic code that looks for contours in the images then measures the lenght of it. After that it decides if it is hairy or not by comparing it with a static treshhold. The code for this can be found in the `search_hair_for_caption.py` file.

# Train
I wanted to use spesifically LoRa for this task because of the following reasons:
- LoRa is less system intensive than other fine-tuning techniques. It can be trained even with the free-tier of Google Colab on a T4 GPU. So it is very accessible.
- LoRa is very fast to train because it doesn't alter the original weights of the model and trains on much smaller number of parameters 
- LoRa is so small in comparison to the other fine-tuning techniques. A traditional checkpoint is around 6 GB, but LoRa is around 100 to 500 MB depending on the network_dim of the model. 

So I wanted test the performance of SDXL with LoRa on the medical field. I used fine-tuning scripts from the [kohya_ss](https://github.com/kohya-ss/sd-scripts) repository[^2]. My configs can be found in the `configs` folder. I trained on T4 GPU for 7200 steps. 

# Results
Some of the sample images can be seen in the 'synthetic_malignant_image_samples' folder. The results are not perfect but I think they are promising. With more diverse captions and data, I think we can get better results.

# Acknowledgement
[^1]: Rotemberg, V., Kurtansky, N., Betz-Stablein, B., Caffery, L., Chousakos, E., Codella, N., Combalia, M., Dusza, S., Guitera, P., Gutman, D., Halpern, A., Helba, B., Kittler, H., Kose, K., Langer, S., Lioprys, K., Malvehy, J., Musthaq, S., Nanda, J., Reiter, O., Shih, G., Stratigos, A., Tschandl, P., Weber, J. & Soyer, P. A patient-centric dataset of images and metadata for identifying melanomas using clinical context. Sci Data 8, 34 (2021). https://doi.org/10.1038/s41597-021-00815-z 

[^2]: LoRa fine-tuning scripts belongs to [kohya_ss](https://github.com/kohya-ss/sd-scripts). You can clone the repository and configure it for your needs.